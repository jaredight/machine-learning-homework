{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"midterm2020fall.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"TzFDXTTnWM9c"},"source":["import numpy as np\n","np.random.seed(seed=484)\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-JYG5qnnWM9f"},"source":["# Midterm Exam"]},{"cell_type":"markdown","metadata":{"id":"-YiFzYF2WM9g"},"source":["Exam is open book, open note, and open Google. You are not allowed outside\n","help from another person, however. All work, including coding, must be yours alone. Remember to turn in both the written portion and this coding portion. The coding portion can be turned in by submitting a shared link to your Colab notebook. To complete this coding portion, make sure to save a copy of this notebook in your own Google drive, supply the python code in the empty cells below, and execute the notebook. To get full credit, the completed notebook should be able to run top to bottom, producing the results asked for in the prompts below."]},{"cell_type":"markdown","metadata":{"id":"MkCjCsX9WM9g"},"source":["This portion of the exam will take you through the steps of the supervised machine learning process."]},{"cell_type":"markdown","metadata":{"id":"UamL0RdiWM9h"},"source":["## 1. Figure out your question"]},{"cell_type":"markdown","metadata":{"id":"LQ7P55DJWM9h"},"source":["The question you want to answer using machine learning is: Would two people with identical observed characteristics but different race be predicted to have their loan applications treated differently?"]},{"cell_type":"markdown","metadata":{"id":"A6zoctZZWM9h"},"source":["## 2. Obtain a labeled dataset"]},{"cell_type":"markdown","metadata":{"id":"SdgfGHzYWM9i"},"source":["Import the python library that is good for manipulating datasets:"]},{"cell_type":"code","metadata":{"id":"y3wmGngUWM9i","executionInfo":{"status":"ok","timestamp":1603404195170,"user_tz":360,"elapsed":40051,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"c8067250-71e4-4595-e150-d028ed9ce2bd","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import sklearn\n","import pandas as pd\n","\n","%matplotlib inline\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd '/content/gdrive/My Drive/Econ 484'\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Econ 484\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AwWVnmc_WM9k"},"source":["Accompanying the exam materials are a spreadsheet of mortgage loan applicants, 'mortgagedenials.csv' and a text file, 'variabledefs.txt' that explains each variable in the spreadsheet. Read in the data in the spreadsheet 'mortgagedenials.csv', print out the first few rows of data with the variable names, and print out the number of observations and variables in the dataset:"]},{"cell_type":"code","metadata":{"id":"Fer02-GdWM9k","executionInfo":{"status":"ok","timestamp":1603404195171,"user_tz":360,"elapsed":40008,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"3b002b3b-c579-4896-e27e-6d8740de8fc8","colab":{"base_uri":"https://localhost:8080/","height":360}},"source":["mdenials = pd.read_csv('mortgagedenials.csv')\n","print(mdenials.head)\n","print(mdenials[:0])\n","print('number of observations: {}'.format(str(mdenials.shape[0] - 1)))\n","print('number of variables: {}'.format(str(mdenials.shape[1])))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<bound method NDFrame.head of       deny  p_irat  black  hse_inc  ...  probunmp  condo  ltv_med  ltv_high\n","0        0  0.2170      0   0.2130  ...       3.2      0        0         0\n","1        0  0.2600      0   0.2200  ...       3.9      0        1         0\n","2        1  0.4600      0   0.2700  ...       5.3      0        1         0\n","3        0  0.4900      0   0.2700  ...       3.2      0        0         0\n","4        0  0.2600      0   0.2600  ...       4.3      0        0         0\n","...    ...     ...    ...      ...  ...       ...    ...      ...       ...\n","2375     0  0.2800      1   0.2400  ...       3.2      1        0         0\n","2376     1  0.3207      1   0.2522  ...       5.3      1        1         0\n","2377     0  0.3810      1   0.2960  ...       3.1      0        1         0\n","2378     0  0.3150      1   0.2870  ...       3.2      0        1         0\n","2379     0  0.3749      1   0.3071  ...       3.1      0        1         0\n","\n","[2380 rows x 16 columns]>\n","Empty DataFrame\n","Columns: [deny, p_irat, black, hse_inc, loan_val, ccred, mcred, pubrec, denpmi, selfemp, single, hischl, probunmp, condo, ltv_med, ltv_high]\n","Index: []\n","number of observations: 2379\n","number of variables: 16\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SQnjWhASWM9m"},"source":["Define a label (outcome) vector, $y$, to be an indicator for whether the individual's mortgage application was denied, and define a feature (regressor) matrix, $X$, to be all remaining columns:"]},{"cell_type":"code","metadata":{"id":"GMpxIqiHWM9m","executionInfo":{"status":"ok","timestamp":1603404195173,"user_tz":360,"elapsed":39961,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"e8afe2a5-6f91-44c8-e056-ebe354ac61a0","colab":{"base_uri":"https://localhost:8080/","height":513}},"source":["y = mdenials.filter(items=['deny'])\n","X = mdenials.loc[:, mdenials.columns != 'deny']\n","print(y.head)\n","print(X.head)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<bound method NDFrame.head of       deny\n","0        0\n","1        0\n","2        1\n","3        0\n","4        0\n","...    ...\n","2375     0\n","2376     1\n","2377     0\n","2378     0\n","2379     0\n","\n","[2380 rows x 1 columns]>\n","<bound method NDFrame.head of       p_irat  black  hse_inc  loan_val  ...  probunmp  condo  ltv_med  ltv_high\n","0     0.2170      0   0.2130  0.638889  ...       3.2      0        0         0\n","1     0.2600      0   0.2200  0.945946  ...       3.9      0        1         0\n","2     0.4600      0   0.2700  0.840000  ...       5.3      0        1         0\n","3     0.4900      0   0.2700  0.199482  ...       3.2      0        0         0\n","4     0.2600      0   0.2600  0.366667  ...       4.3      0        0         0\n","...      ...    ...      ...       ...  ...       ...    ...      ...       ...\n","2375  0.2800      1   0.2400  0.438462  ...       3.2      1        0         0\n","2376  0.3207      1   0.2522  0.900000  ...       5.3      1        1         0\n","2377  0.3810      1   0.2960  0.897436  ...       3.1      0        1         0\n","2378  0.3150      1   0.2870  0.901316  ...       3.2      0        1         0\n","2379  0.3749      1   0.3071  0.878431  ...       3.1      0        1         0\n","\n","[2380 rows x 15 columns]>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4OEvMdp-Xj6m"},"source":["\"Pre-process\" your features, $X$, by standardizing them to have zero mean and unit variance. Hint: you may import a useful package to do this."]},{"cell_type":"code","metadata":{"id":"rNiZolJcXv6C","executionInfo":{"status":"ok","timestamp":1603404195496,"user_tz":360,"elapsed":40255,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"4fb5209c-c3c9-4019-c08f-b988ce3ff8ed","colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit(X)\n","x_scaled = scaler.transform(X)\n","print(x_scaled)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[-1.06134959 -0.40754761 -0.4382055  ... -0.63636364 -0.77355554\n","  -0.18285144]\n"," [-0.66036035 -0.40754761 -0.3657682  ... -0.63636364  1.29273199\n","  -0.18285144]\n"," [ 1.20470691 -0.40754761  0.15164115 ... -0.63636364  1.29273199\n","  -0.18285144]\n"," ...\n"," [ 0.46800513  2.45370108  0.42069386 ... -0.63636364  1.29273199\n","  -0.18285144]\n"," [-0.14746681  2.45370108  0.32756019 ... -0.63636364  1.29273199\n","  -0.18285144]\n"," [ 0.41112087  2.45370108  0.53555871 ... -0.63636364  1.29273199\n","  -0.18285144]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cSuEbRMKWM9o"},"source":["## 3. Divide into training and set sets"]},{"cell_type":"markdown","metadata":{"id":"mi-dbFQyWM9o"},"source":["Import the python library that is good for randomly splitting datasets into training and test sets:"]},{"cell_type":"code","metadata":{"id":"cpTtWuWsWM9p"},"source":["from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qw5tGzFUWM9r"},"source":["Now make a training and test feature matrix and a training and test label vector:"]},{"cell_type":"code","metadata":{"id":"im4z_YPAWM9r"},"source":["X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, stratify=y, random_state=24)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FzVMOGgrWM9t"},"source":["## 4. Pick an appropriate method"]},{"cell_type":"markdown","metadata":{"id":"VbrMr8KFWM9t"},"source":["Choose a method appropriate for classification and import its library:"]},{"cell_type":"code","metadata":{"id":"g0rbHexoWM9u"},"source":["from sklearn.ensemble import RandomForestClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tI0muOgJWM9y"},"source":["## 5. Choose regularization parameters via cross-validation on the training set"]},{"cell_type":"markdown","metadata":{"id":"JT5ASK5pWM9y"},"source":["Search over a grid of values of the regularization parameters for the parameters that perform the best on the left-out folds:"]},{"cell_type":"code","metadata":{"id":"vW02SXYn1J38"},"source":["\n","# I USED THIS CODE TO GET AN IDEA OF THE VALUES I SHOULD USE IN THE GRID\n","#BUT IT TAKES A LONG TIME TO RUN\n","\n","#from sklearn.model_selection import RandomizedSearchCV\n","\n","#n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 10)]\n","#max_features = ['auto', 'sqrt']\n","#max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n","#max_depth.append(None)\n","#min_samples_split = [2, 5, 10]\n","#min_samples_leaf = [1, 2, 4]\n","#bootstrap = [True, False]\n","#random_grid = {'n_estimators': n_estimators,\n","#               'max_features': max_features,\n","#               'max_depth': max_depth,\n","#               'min_samples_split': min_samples_split,\n","#               'min_samples_leaf': min_samples_leaf,\n","#               'bootstrap': bootstrap}\n","\n","#rf = RandomForestClassifier(random_state=24)\n","#rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,\n","#                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n","\n","#rf_random.fit(X_train, y_train)\n","#print(rf_random.best_params_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"--bUGbFL7IRr"},"source":["from sklearn.model_selection import GridSearchCV\n","# Create the parameter grid based on the results of random search \n","param_grid = {\n","    'max_depth': [15,20,25],\n","    'max_features': [5,10,15],\n","    'min_samples_split': [3,5,8]\n","}\n","\n","rf = RandomForestClassifier()\n","# grid search model with 3 folds\n","grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQNSJB1D55Os","executionInfo":{"status":"ok","timestamp":1603404225479,"user_tz":360,"elapsed":70118,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"21a6e884-030d-41f3-a52c-3279d6eb029d","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["grid_search.fit(X_train, y_train)\n","print(grid_search.best_params_)\n","\n","#This takes a while to run too..."],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'max_depth': 20, 'max_features': 5, 'min_samples_split': 8}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4tYVe5fLWM90"},"source":["## 6. Fit model on whole training set using the cross-validated parameters"]},{"cell_type":"code","metadata":{"id":"JUKuEKLoWM90","executionInfo":{"status":"ok","timestamp":1603404230344,"user_tz":360,"elapsed":74915,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"de84acc0-ce8a-46b3-83f1-726f70e51f85","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["rf = RandomForestClassifier(max_depth= 15, n_estimators=1500,\n","                            min_samples_split = 3, max_features = 5, random_state=24)\n","rf.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=15, max_features=5,\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=3,\n","                       min_weight_fraction_leaf=0.0, n_estimators=1500,\n","                       n_jobs=None, oob_score=False, random_state=24, verbose=0,\n","                       warm_start=False)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"0Qg1nZnpWM92"},"source":["## 7. Evaluate model by applying it to test set"]},{"cell_type":"markdown","metadata":{"id":"OA7l42zLWM92"},"source":["Compute and print out the \"score\" of the model applied to the test set:"]},{"cell_type":"code","metadata":{"id":"I-LocbNpWM92","executionInfo":{"status":"ok","timestamp":1603404231238,"user_tz":360,"elapsed":75790,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"62383219-f7d4-4488-bae1-c0fca2f52136","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(\"Accuracy on training set: {:.3f}\".format(rf.score(X_train, y_train)))\n","print(\"Accuracy on test set: {:.4f}\".format(rf.score(X_test, y_test)))\n","\n","#Accuracy on training set: 0.984\n","#Accuracy on test set: 0.9210"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on training set: 0.984\n","Accuracy on test set: 0.9210\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U2fXVbgRWM94"},"source":["## 8. Repeat 4-7 for another method"]},{"cell_type":"markdown","metadata":{"id":"-yHi6UvEWM95"},"source":["Import the method's library, do cross validation to find tuning parameters, fit the model on the training data using the cross-validated tuning parameters, and compute (and report) the model's score on the test set:"]},{"cell_type":"code","metadata":{"id":"sQbfbPeqWM95"},"source":["from sklearn.svm import SVC\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddf5eYIrE_yp"},"source":["from sklearn.model_selection import GridSearchCV\n","# Create the parameter grid based on the results of random search \n","param_grid = {\n","    'C': [1, 2, 4, 5, 10, 25],\n","    'kernel': ['linear','rbf'],\n","    'gamma': [0.001, 0.0001]\n","}\n","\n","lsvc = SVC()\n","# Instantiate the grid search model with 3 folds\n","grid_search = GridSearchCV(estimator = lsvc, param_grid = param_grid, cv = 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZaUt6w8RtKw","executionInfo":{"status":"ok","timestamp":1603404234927,"user_tz":360,"elapsed":79449,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"ee9a4aaf-6f70-4589-e477-4177da360186","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["grid_search.fit(X_train, y_train)\n","print(grid_search.best_params_)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vkgNYKaGFERA","executionInfo":{"status":"ok","timestamp":1603404234929,"user_tz":360,"elapsed":79438,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"4ec934cd-04a3-4e54-adc0-9ccca765960e","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["lsvc = SVC(C= 1, gamma= 0.001, kernel= 'linear', random_state=24)\n","lsvc.fit(X_train, y_train)\n","\n","print(\"Accuracy on training set: {:.3f}\".format(lsvc.score(X_train, y_train)))\n","print(\"Accuracy on test set: {:.4f}\".format(lsvc.score(X_test, y_test)))\n","#Accuracy on training set: 0.894\n","#Accuracy on test set: 0.9059"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on training set: 0.894\n","Accuracy on test set: 0.9059\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rhyyawznWM96"},"source":["## 9. Apply the chosen method to new observations for which we have no labels"]},{"cell_type":"markdown","metadata":{"id":"U1xH4EB6WM97"},"source":["Fit the method you chose (based on performance on the test set) to your entire dataset:"]},{"cell_type":"code","metadata":{"id":"LuYK8wA6WM97","executionInfo":{"status":"ok","timestamp":1603404240961,"user_tz":360,"elapsed":85451,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"46ada60f-2ef9-4428-95e4-51932b7fe9d5","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["rf = RandomForestClassifier(max_depth= 15, n_estimators=1500,\n","                            min_samples_split = 8, max_features=5, random_state=24)\n","rf.fit(x_scaled, y)\n","\n","#lsvc = SVC(C= 1, gamma= 0.001, kernel= 'linear', random_state=24)\n","#lsvc.fit(x_scaled, y)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=15, max_features=5,\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=8,\n","                       min_weight_fraction_leaf=0.0, n_estimators=1500,\n","                       n_jobs=None, oob_score=False, random_state=24, verbose=0,\n","                       warm_start=False)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"wzPB_fH7WM99"},"source":["The spreadsheet 'newapplicants.csv' contains information on two new mortgage applicants, the first black, the second non-black, but who otherwise share identical characteristics, namely, they both have monthly debt-to-income and housing expenses to income ratio of .25, both have a loan to property value ratio of .951, both have a category 4 credit and mortgage score, neither has a public record of credit problems, neither was denied mortgage insurance, both are self-employed, both are single, neither graduated from high school, both have occupations with an industry unemployment rate of 9, and neither is purchasing a condo."]},{"cell_type":"markdown","metadata":{"id":"fvZIvvAbWM99"},"source":["Read in the new applicant information and apply the chosen model to predict whether each applicant will be denied or not, and print out the predictions. Hint: don't forget to apply the same pre-processing steps to the new observations as you did to your training and test observations. This means standardizing the new observations using the means and variances of your labeled dataset, not the means and variances of these two new observations."]},{"cell_type":"code","metadata":{"hide_input":false,"id":"6EV3sNlRWM99","executionInfo":{"status":"ok","timestamp":1603404240969,"user_tz":360,"elapsed":85443,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"5db6896c-6d28-41a9-9ce5-3f168cafce74","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["newapplicants = pd.read_csv('newapplicants.csv')\n","print(newapplicants.head)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<bound method NDFrame.head of    p_irat  black  hse_inc  loan_val  ...  probunmp  condo  ltv_med  ltv_high\n","0    0.25      1     0.25     0.951  ...         9      0        0         1\n","1    0.25      0     0.25     0.951  ...         9      0        0         1\n","\n","[2 rows x 15 columns]>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IFvy6Abbjbxw","executionInfo":{"status":"ok","timestamp":1603404734695,"user_tz":360,"elapsed":810,"user":{"displayName":"Jared Wright","photoUrl":"","userId":"10392668584407943168"}},"outputId":"861c7042-0851-40b6-eb88-909623c3376c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["scaler = StandardScaler()\n","scaler.fit(X)\n","newapps_scaled = scaler.transform(newapplicants)\n","\n","print(rf.predict(newapps_scaled))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eC1dWoGPWM9_"},"source":["Do the predictions differ between the black and non-black applicant, and what if anything does this suggest about the fairness of the mortgage application process?"]},{"cell_type":"markdown","metadata":{"id":"e1gP8SkZWM9_"},"source":["my predictions do indeed differ. This suggests that the mortgage application process is unfair, at least for the specific type of individual we look at. To see what the model says in general we would have to test the model on many different values of each variable. (i.e. we would do what we did with the new applicants data except with many different sets of identical black and white individuals.)"]}]}